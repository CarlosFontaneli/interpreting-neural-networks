{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit http://127.0.0.1:8050/ in your web browser.\n",
    "# Imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "# Add the upper directory to the path\n",
    "sys.path.append(\"../../models/\")\n",
    "from CustomCNNVessel import CustomResNet\n",
    "sys.path.append(\"../../data/\")\n",
    "from VessMapDatasetLoader import vess_map_dataloader\n",
    "\n",
    "import dash\n",
    "from dash import html, dcc, Dash, html, dcc, Input, Output, callback, State\n",
    "from dash.dependencies import Input, Output, MATCH\n",
    "import plotly.express as px\n",
    "import json\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "image_dir = '/home/fonta42/Desktop/interpretacao-redes-neurais/data/VessMap/images'\n",
    "mask_dir = '/home/fonta42/Desktop/interpretacao-redes-neurais/data/VessMap/labels'\n",
    "skeleton_dir = '/home/fonta42/Desktop/interpretacao-redes-neurais/data/VessMap/skeletons'\n",
    "\n",
    "batch_size = 10\n",
    "train_size = 0.8\n",
    "\n",
    "train_loader, test_loader = vess_map_dataloader(image_dir, \n",
    "                                  mask_dir, \n",
    "                                  skeleton_dir, \n",
    "                                  batch_size,\n",
    "                                  train_size = train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concating images\n",
    "all_images = []\n",
    "all_masks = []\n",
    "all_skeletons = []\n",
    "\n",
    "# Iterate through the entire train_loader\n",
    "for batch in train_loader:\n",
    "    images, masks, skeletons = batch\n",
    "    images, masks, skeletons = images.to(device), masks.to(device), skeletons.to(device)\n",
    "\n",
    "    all_images.extend(images)\n",
    "    all_masks.extend(masks)\n",
    "    all_skeletons.extend(skeletons)\n",
    "    \n",
    "for batch in test_loader:\n",
    "    images, masks, skeletons = batch\n",
    "    images, masks, skeletons = images.to(device), masks.to(device), skeletons.to(device)\n",
    "\n",
    "    all_images.extend(images)\n",
    "    all_masks.extend(masks)\n",
    "    all_skeletons.extend(skeletons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def load_images_from_directory(directory_name):\n",
    "    # Get the list of image file names in sorted order\n",
    "    image_files = sorted(os.listdir(directory_name))\n",
    "\n",
    "    # Load and store the images in a list\n",
    "    images = []\n",
    "    for file_name in image_files:\n",
    "        if file_name.endswith('.png'):\n",
    "            img_path = os.path.join(directory_name, file_name)\n",
    "            img = Image.open(img_path)\n",
    "            img_array = np.array(img)\n",
    "            images.append(img_array)\n",
    "\n",
    "    return images\n",
    "\n",
    "# Load images from both directories\n",
    "original_images = load_images_from_directory('../original_images')\n",
    "fulfillment_images = load_images_from_directory('../fulfillment_images')\n",
    "\n",
    "# Convert the lists to arrays if needed\n",
    "original_images = torch.tensor(np.array(original_images) / 255.0, dtype=torch.float).to('cuda')\n",
    "fulfillment_images = torch.tensor(np.array(fulfillment_images) / 255.0, dtype=torch.float).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulfillment_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "model = CustomResNet(num_classes=2).to(device)\n",
    "# Load the weights\n",
    "model.load_state_dict(torch.load(f\"../../models/vess_map_regularized_none_200.pth\"))\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def get_all_gradients(model, image, sampling_rate = 10, device = \"cuda\", vectorize = True):\\n  model.to(device)\\n  image = image.to(device).requires_grad()\\n  \\n  sampled_image = image[:,:,::sampling_rate,::sampling_rate]\\n  jacobian_gradient = torch.autograd.functional.jacobian(model, \\n                                                         sampled_image,\\n                                                         vectorize = vectorize)\\n  jacobian_gradient = jacobian_gradient.squeeze()\\n  \\n  return jacobian_gradient '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def get_all_gradients(model, image, sampling_rate = 10, device = \"cuda\", vectorize = True):\n",
    "  model.to(device)\n",
    "  image = image.to(device).requires_grad()\n",
    "  \n",
    "  sampled_image = image[:,:,::sampling_rate,::sampling_rate]\n",
    "  jacobian_gradient = torch.autograd.functional.jacobian(model, \n",
    "                                                         sampled_image,\n",
    "                                                         vectorize = vectorize)\n",
    "  jacobian_gradient = jacobian_gradient.squeeze()\n",
    "  \n",
    "  return jacobian_gradient \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gradients_with_bounding_box(gradient, model_name, threshold=0.01):\n",
    "    gradient = gradient.squeeze()\n",
    "    mask = np.abs(gradient) > threshold\n",
    "    non_zero_coords = np.nonzero(mask)\n",
    "    \n",
    "    if len(non_zero_coords[0]) > 0:\n",
    "        y_min, y_max = non_zero_coords[0].min(), non_zero_coords[0].max()\n",
    "        x_min, x_max = non_zero_coords[1].min(), non_zero_coords[1].max()\n",
    "        num_pixels_above_threshold = np.sum(mask)\n",
    "        bounding_box_area = (y_max - y_min + 1) * (x_max - x_min + 1)\n",
    "        fulfillment = num_pixels_above_threshold / bounding_box_area\n",
    "\n",
    "        # Create the figure using Plotly Express\n",
    "        fig = px.imshow(\n",
    "            gradient[y_min:y_max+1, x_min:x_max+1],\n",
    "            title=f'Gradient Analysis for {model_name}',\n",
    "            labels={'x': 'x-axis', 'y': 'y-axis'},\n",
    "            color_continuous_scale=px.colors.diverging.RdYlGn,\n",
    "            range_color=[-np.abs(gradient).max(), np.abs(gradient).max()],\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            annotations=[{\n",
    "                'text': f\"Pixels: {num_pixels_above_threshold}<br>\"\n",
    "                        f\"Area: {bounding_box_area}<br>\"\n",
    "                        f\"Fulfillment: {fulfillment:.2f}<br>\"\n",
    "                        f\"Threshold: {threshold:.4f}<br>\",\n",
    "                'showarrow': False,\n",
    "                'xref': 'paper',\n",
    "                'yref': 'paper',\n",
    "                'x': 0, 'y': 1,\n",
    "                'xanchor': 'left', 'yanchor': 'top',\n",
    "                'font': {'size': 12, 'color': 'black'},\n",
    "                'bgcolor': 'white',\n",
    "                'opacity': 0.7\n",
    "            }],\n",
    "            xaxis={'visible': False},\n",
    "            yaxis={'visible': False},\n",
    "        )\n",
    "        return fig\n",
    "    else:\n",
    "        return px.imshow(torch.zeros(224, 224), color_continuous_scale=px.colors.sequential.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d6d70113b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "TypeError                                 Traceback (most recent call last)\n",
      "~/anaconda3/envs/interpreting-cnn/lib/python3.7/json/__init__.py in loads(\n",
      "    s=None,\n",
      "    encoding=None,\n",
      "    cls=None,\n",
      "    object_hook=None,\n",
      "    parse_float=None,\n",
      "    parse_int=None,\n",
      "    parse_constant=None,\n",
      "    object_pairs_hook=None,\n",
      "    **kw={}\n",
      ")\n",
      "    339     else:\n",
      "    340         if not isinstance(s, (bytes, bytearray)):\n",
      "--> 341             raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
      "        global TypeError = undefined\n",
      "    342                             f'not {s.__class__.__name__}')\n",
      "    343         s = s.decode(detect_encoding(s), 'surrogatepass')\n",
      "\n",
      "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TypeError                                 Traceback (most recent call last)\n",
      "~/anaconda3/envs/interpreting-cnn/lib/python3.7/json/__init__.py in loads(\n",
      "    s=None,\n",
      "    encoding=None,\n",
      "    cls=None,\n",
      "    object_hook=None,\n",
      "    parse_float=None,\n",
      "    parse_int=None,\n",
      "    parse_constant=None,\n",
      "    object_pairs_hook=None,\n",
      "    **kw={}\n",
      ")\n",
      "    339     else:\n",
      "    340         if not isinstance(s, (bytes, bytearray)):\n",
      "--> 341             raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
      "        global TypeError = undefined\n",
      "    342                             f'not {s.__class__.__name__}')\n",
      "    343         s = s.decode(detect_encoding(s), 'surrogatepass')\n",
      "\n",
      "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TypeError                                 Traceback (most recent call last)\n",
      "~/anaconda3/envs/interpreting-cnn/lib/python3.7/json/__init__.py in loads(\n",
      "    s=None,\n",
      "    encoding=None,\n",
      "    cls=None,\n",
      "    object_hook=None,\n",
      "    parse_float=None,\n",
      "    parse_int=None,\n",
      "    parse_constant=None,\n",
      "    object_pairs_hook=None,\n",
      "    **kw={}\n",
      ")\n",
      "    339     else:\n",
      "    340         if not isinstance(s, (bytes, bytearray)):\n",
      "--> 341             raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
      "        global TypeError = undefined\n",
      "    342                             f'not {s.__class__.__name__}')\n",
      "    343         s = s.decode(detect_encoding(s), 'surrogatepass')\n",
      "\n",
      "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TypeError                                 Traceback (most recent call last)\n",
      "~/anaconda3/envs/interpreting-cnn/lib/python3.7/json/__init__.py in loads(\n",
      "    s=None,\n",
      "    encoding=None,\n",
      "    cls=None,\n",
      "    object_hook=None,\n",
      "    parse_float=None,\n",
      "    parse_int=None,\n",
      "    parse_constant=None,\n",
      "    object_pairs_hook=None,\n",
      "    **kw={}\n",
      ")\n",
      "    339     else:\n",
      "    340         if not isinstance(s, (bytes, bytearray)):\n",
      "--> 341             raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
      "        global TypeError = undefined\n",
      "    342                             f'not {s.__class__.__name__}')\n",
      "    343         s = s.decode(detect_encoding(s), 'surrogatepass')\n",
      "\n",
      "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TypeError                                 Traceback (most recent call last)\n",
      "~/anaconda3/envs/interpreting-cnn/lib/python3.7/json/__init__.py in loads(\n",
      "    s=None,\n",
      "    encoding=None,\n",
      "    cls=None,\n",
      "    object_hook=None,\n",
      "    parse_float=None,\n",
      "    parse_int=None,\n",
      "    parse_constant=None,\n",
      "    object_pairs_hook=None,\n",
      "    **kw={}\n",
      ")\n",
      "    339     else:\n",
      "    340         if not isinstance(s, (bytes, bytearray)):\n",
      "--> 341             raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
      "        global TypeError = undefined\n",
      "    342                             f'not {s.__class__.__name__}')\n",
      "    343         s = s.decode(detect_encoding(s), 'surrogatepass')\n",
      "\n",
      "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "TypeError                                 Traceback (most recent call last)\n",
      "~/anaconda3/envs/interpreting-cnn/lib/python3.7/json/__init__.py in loads(\n",
      "    s=None,\n",
      "    encoding=None,\n",
      "    cls=None,\n",
      "    object_hook=None,\n",
      "    parse_float=None,\n",
      "    parse_int=None,\n",
      "    parse_constant=None,\n",
      "    object_pairs_hook=None,\n",
      "    **kw={}\n",
      ")\n",
      "    339     else:\n",
      "    340         if not isinstance(s, (bytes, bytearray)):\n",
      "--> 341             raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
      "        global TypeError = undefined\n",
      "    342                             f'not {s.__class__.__name__}')\n",
      "    343         s = s.decode(detect_encoding(s), 'surrogatepass')\n",
      "\n",
      "TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "\n"
     ]
    }
   ],
   "source": [
    "app = Dash(__name__)\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div(\n",
    "    style={\n",
    "        'display': 'flex',\n",
    "        'flex-direction': 'column',\n",
    "        'align-items': 'center',\n",
    "        'height': '100vh',\n",
    "        'width': '100vw'\n",
    "    },\n",
    "    children=[\n",
    "        html.H1(\"Dynamic Gradient Plots\"),\n",
    "        html.Div(\n",
    "            style={\n",
    "                'display': 'flex',\n",
    "                'flex-direction': 'row',\n",
    "                'justify-content': 'space-around',\n",
    "                'width': '90%',\n",
    "                'margin-bottom': '20px',\n",
    "                'align-items': 'center'\n",
    "            },\n",
    "            children=[\n",
    "                dcc.Dropdown(\n",
    "                    id='image-dropdown',\n",
    "                    options=[{'label': f'Image {i}', 'value': i} for i in range(len(original_images))],\n",
    "                    value=0,\n",
    "                    style={'width': '80%', 'flex': '1'}\n",
    "                ),\n",
    "                dcc.Input(\n",
    "                    id='threshold-input',\n",
    "                    type='number',\n",
    "                    placeholder='Enter the proportion of max gradient value',\n",
    "                    debounce=True,\n",
    "                    min=0,\n",
    "                    step=0.001,\n",
    "                    value=0.005,\n",
    "                    style={'width': '80%', 'flex': '1'}\n",
    "                ),\n",
    "                html.Button(\n",
    "                    'Update',\n",
    "                    id='update-button',\n",
    "                    n_clicks=0,\n",
    "                    style={'width': '80%', 'flex': '1'}\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        html.Div(\n",
    "            style={\n",
    "                'display': 'flex',\n",
    "                'flex-direction': 'row',\n",
    "                'justify-content': 'space-between',\n",
    "                'width': '95vw',\n",
    "                'height': '80vh',\n",
    "            },\n",
    "            children=[\n",
    "                html.Div(\n",
    "                    [\n",
    "                        html.H2(\"Original Image\"),\n",
    "                        dcc.Graph(\n",
    "                            id='image-display',\n",
    "                            config={'displayModeBar': True},\n",
    "                            style={'height': '100%'}\n",
    "                        ),\n",
    "                        html.Div(id='hover-data', style={'display': 'none'})\n",
    "                    ],\n",
    "                    style={'flex': '1', 'margin-right': '10px'}\n",
    "                ),\n",
    "                html.Div(\n",
    "                    [\n",
    "                        html.H2(\"Fulfillment Image\"),\n",
    "                        dcc.Graph(\n",
    "                            id='fulfillment-image-display',\n",
    "                            config={'displayModeBar': True},\n",
    "                            style={'height': '100%'}\n",
    "                        ),\n",
    "                    ],\n",
    "                    style={'flex': '1', 'margin-right': '10px'}\n",
    "                ),\n",
    "                html.Div(\n",
    "                    [\n",
    "                        html.H2(id='hover-coordinates', children='Coordinates: (x, y)'),\n",
    "                        dcc.Graph(\n",
    "                            id='result-image-display',\n",
    "                            config={'displayModeBar': True},\n",
    "                            style={'height': '100%'}\n",
    "                        )\n",
    "                    ],\n",
    "                    style={'flex': '1', 'margin-right': '10px'}\n",
    "                ),\n",
    "                html.Div(\n",
    "                    [\n",
    "                        html.H2(id='threshold-title', children=\"Scale Delimited Gradient (Threshold: 0)\"),\n",
    "                        dcc.Graph(\n",
    "                            id='gradient-display',\n",
    "                            config={'displayModeBar': True},\n",
    "                            style={'height': '100%'}\n",
    "                        )\n",
    "                    ],\n",
    "                    style={'flex': '1'}\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Callback to update the original image based on the dropdown selection\n",
    "@app.callback(\n",
    "    Output('image-display', 'figure'),\n",
    "    Output('fulfillment-image-display', 'figure'),\n",
    "    Input('image-dropdown', 'value')\n",
    ")\n",
    "def update_images(selected_index):\n",
    "    original_image_data = original_images[selected_index].squeeze()\n",
    "    fulfillment_image_data = fulfillment_images[selected_index]\n",
    "    original_fig = px.imshow(original_image_data.to('cpu'), color_continuous_scale=px.colors.sequential.gray)\n",
    "    fulfillment_fig = px.imshow(fulfillment_image_data[:, :, :3].to('cpu'), color_continuous_scale=px.colors.diverging.RdYlGn)\n",
    "    return original_fig, fulfillment_fig\n",
    "\n",
    "# Define callback to update the hover data\n",
    "@app.callback(\n",
    "    Output('hover-data', 'children'),\n",
    "    Input('image-display', 'hoverData'),\n",
    "    Input('fulfillment-image-display', 'hoverData')\n",
    ")\n",
    "def store_hover_data(hover_data_original, hover_data_fulfillment):\n",
    "    hover_data = hover_data_original or hover_data_fulfillment\n",
    "    if hover_data:\n",
    "        return json.dumps({'x': hover_data['points'][0]['x'], 'y': hover_data['points'][0]['y']})\n",
    "    return \"{}\"\n",
    "\n",
    "# Define callback to update the hover coordinates display\n",
    "@app.callback(\n",
    "    Output('hover-coordinates', 'children'),\n",
    "    Input('hover-data', 'children')\n",
    ")\n",
    "def update_hover_coordinates(hover_data_json):\n",
    "    hover_data = json.loads(hover_data_json)\n",
    "    if hover_data:\n",
    "        x, y = hover_data['x'], hover_data['y']\n",
    "        return f'Full Gradient, at Coordinates: ({x}, {y})'\n",
    "    return 'Full Gradient, Coordinates: (x, y)'\n",
    "\n",
    "# Define callback to update the result image\n",
    "@app.callback(\n",
    "    Output('result-image-display', 'figure'),\n",
    "    Input('update-button', 'n_clicks'),\n",
    "    Input('hover-data', 'children'),\n",
    "    Input('image-dropdown', 'value'),\n",
    ")\n",
    "def update_image(n_clicks, hover_data_json, selected_index):\n",
    "    hover_data = json.loads(hover_data_json)\n",
    "    if hover_data:\n",
    "        x, y = hover_data['x'], hover_data['y']\n",
    "        image_data = original_images[selected_index].unsqueeze(0)\n",
    "        # Ensure image requires gradient\n",
    "        image = image_data.unsqueeze(0).requires_grad_()\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(image)\n",
    "\n",
    "        # Apply softmax to the output to get class probabilities\n",
    "        probabilities = F.softmax(out, dim=1)\n",
    "\n",
    "        score = probabilities[0, 1, x, y]  # Probability of class 1 at (x, y)\n",
    "\n",
    "        # Compute gradients\n",
    "        score.backward()\n",
    "\n",
    "        fig = px.imshow(image.grad.squeeze().to('cpu'), color_continuous_scale=px.colors.diverging.RdYlGn)\n",
    "        return fig\n",
    "    return px.imshow(torch.zeros(224, 224), color_continuous_scale=px.colors.diverging.RdYlGn)\n",
    "\n",
    "# Define callback to update the gradient display and the threshold title\n",
    "@app.callback(\n",
    "    Output('gradient-display', 'figure'),\n",
    "    Output('threshold-title', 'children'),\n",
    "    Input('hover-data', 'children'),\n",
    "    Input('threshold-input', 'value'),\n",
    "    Input('image-dropdown', 'value')\n",
    ")\n",
    "def update_gradient_display(hover_data_json, threshold, selected_index):\n",
    "    hover_data = json.loads(hover_data_json)\n",
    "    if hover_data:\n",
    "        x, y = hover_data['x'], hover_data['y']\n",
    "        image_data = original_images[selected_index].unsqueeze(0)\n",
    "        # Ensure image requires gradient\n",
    "        image = image_data.unsqueeze(0).requires_grad_()\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(image)\n",
    "        \n",
    "        # Apply softmax to the output to get class probabilities\n",
    "        probabilities = F.softmax(out, dim=1)\n",
    "\n",
    "        score = probabilities[0, 1, x, y]  # Probability of class 1 at (x, y)\n",
    "\n",
    "        # Compute gradients\n",
    "        score.backward()\n",
    "\n",
    "        # Update the threshold if provided\n",
    "        if threshold is not None:\n",
    "            gradients = [image.grad.squeeze().to('cpu').numpy()]\n",
    "            gradients = [np.abs(gradient) for gradient in gradients]\n",
    "            max_val = np.max([np.max(gradient) for gradient in gradients])\n",
    "            threshold = threshold * max_val\n",
    "            \n",
    "        else:\n",
    "            threshold = 0.001\n",
    "\n",
    "        # Return the gradient with the diverging color map\n",
    "        fig = plot_gradients_with_bounding_box(image.grad.squeeze().to('cpu').numpy(),\"Model\", threshold=threshold)\n",
    "        fig.update_layout(\n",
    "            title=f\"Scale Delimited Gradient (Threshold: {threshold:.3f})\"\n",
    "        )\n",
    "        return fig, f\"Scale Delimited Gradient (Threshold: {threshold:.3f})\"\n",
    "    return px.imshow(torch.zeros(224, 224), color_continuous_scale=px.colors.diverging.RdYlGn), \"Scale Delimited Gradient (Threshold: 0)\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpreting-cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
