{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit http://127.0.0.1:8050/ in your web browser.\n",
    "# Imports\n",
    "import torch\n",
    "from torch.autograd.functional import jacobian\n",
    "import torch.nn.functional as F\n",
    "import cv2 \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "# Add the upper directory to the path\n",
    "sys.path.append(\"../../models/\")\n",
    "from CustomCNNVessel import CustomResNet\n",
    "sys.path.append(\"../../data/\")\n",
    "from VessMapDatasetLoader import vess_map_dataloader\n",
    "\n",
    "import dash\n",
    "from dash import html, dcc, Dash, html, dcc, Input, Output, callback, State\n",
    "from dash.dependencies import Input, Output, MATCH\n",
    "import plotly.express as px\n",
    "import json\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Old Model\\nmodel_custom_net = CustomResNet(num_classes=2).to(device)\\n# Load the weights\\nmodel_custom_net.load_state_dict(torch.load(f\"../../models/vess_map_regularized_none_200.pth\"))\\nmodel_custom_net = model_custom_net.eval() '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Old Model\n",
    "model_custom_net = CustomResNet(num_classes=2).to(device)\n",
    "# Load the weights\n",
    "model_custom_net.load_state_dict(torch.load(f\"../../models/vess_map_regularized_none_200.pth\"))\n",
    "model_custom_net = model_custom_net.eval() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented train model\n",
    "sys.path.append(\"/home/fonta42/Desktop/interpretacao-redes-neurais/models/augmented_vessels_trained_models/inferencia_baseline\")\n",
    "import torchtrainer\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# instanciando o modelo\n",
    "model_layers = (1, 1, 1)\n",
    "model_channels = (64, 64, 64)\n",
    "model_augment = torchtrainer.models.resunet.ResUNetV2((8,), (1,), (64,)).to('cuda')\n",
    "# carregando o state_dict\n",
    "baseline_state_dict = torch.load('/home/fonta42/Desktop/interpretacao-redes-neurais/models/augmented_vessels_trained_models/inferencia_baseline/unetv2_baseline/checkpoint_best.pth')['model']\n",
    "model_augment.load_state_dict(baseline_state_dict)\n",
    "model_augment.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchseg\n",
    "\n",
    "pretrained_unet_restnet_model = torchseg.Unet(\n",
    "    encoder_name=\"resnet18\",\n",
    "    encoder_weights=True,\n",
    "    in_channels=1,\n",
    "    classes=2,\n",
    ").to('cuda')\n",
    "\n",
    "pretrained_unet_restnet_model.load_state_dict(torch.load(\"/home/fonta42/Desktop/interpretacao-redes-neurais/models/torchseg/pretrained_unet_resnet.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_restnet_model = torchseg.Unet(\n",
    "    encoder_name=\"resnet18\",\n",
    "    encoder_weights=False,\n",
    "    in_channels=1,\n",
    "    classes=2,\n",
    ").to('cuda')\n",
    "\n",
    "unet_restnet_model.load_state_dict(torch.load(\"/home/fonta42/Desktop/interpretacao-redes-neurais/models/torchseg/unet_resnet.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original Images\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def load_images_from_directory(directory_name):\n",
    "    # Get the list of image file names in sorted order\n",
    "    image_files = sorted(os.listdir(directory_name))\n",
    "\n",
    "    # Load and store the images in a list\n",
    "    images = []\n",
    "    for file_name in image_files:\n",
    "        if file_name.endswith('.png'):\n",
    "            img_path = os.path.join(directory_name, file_name)\n",
    "            img = Image.open(img_path)\n",
    "            img_array = np.array(img)\n",
    "            images.append(img_array)\n",
    "\n",
    "    return images\n",
    "\n",
    "# Load images from both directories\n",
    "original_images = load_images_from_directory('../cropped_images')\n",
    "\n",
    "# Convert the lists to arrays if needed\n",
    "original_images = torch.tensor(np.array(original_images) / 255.0, dtype=torch.float).to('cuda')\n",
    "original_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 128, 128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Augmented Vessels\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_and_plot_images(directory, plot, image_names = []):\n",
    "    # List to hold images as numpy arrays\n",
    "    image_list = []\n",
    "    \n",
    "    # Loop over all files in the directory\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.tiff'):\n",
    "            # Full path to the image\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            image_names.append(file_path)\n",
    "            \n",
    "    image_names.sort()\n",
    "    \n",
    "    for file_path in image_names: \n",
    "        # Open the image and convert to a numpy array\n",
    "        image = Image.open(file_path)\n",
    "        image_np = np.array(image)\n",
    "        image_list.append(image_np)\n",
    "        \n",
    "        if plot:\n",
    "            # Plotting the image\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(image_np, cmap='gray')\n",
    "            plt.title(file_name)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "    \n",
    "    return image_list, image_names\n",
    "\n",
    "# Usage\n",
    "directory = '/home/fonta42/Desktop/interpretacao-redes-neurais/data/augmented_vessels'\n",
    "original_images, image_names = load_and_plot_images(directory, plot = False)\n",
    "\n",
    "\n",
    "# Convert the lists to arrays if needed\n",
    "original_images = torch.tensor(np.array(original_images) / 255.0, dtype=torch.float).to('cuda')\n",
    "original_images.shape\n",
    "# TODO: run for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" fulfillment_images = []\\nfor i in range(100):\\n  fulfillment_images.append(np.load(f'../fulfillment_images/image_{i}.npy'))\\n\\nfulfillment_images = np.array(fulfillment_images)\\n\\nfulfillment_images.shape \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original images\n",
    "\"\"\" fulfillment_images = []\n",
    "for i in range(100):\n",
    "  fulfillment_images.append(np.load(f'../fulfillment_images/image_{i}.npy'))\n",
    "\n",
    "fulfillment_images = np.array(fulfillment_images)\n",
    "\n",
    "fulfillment_images.shape \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nfulfillment_images = []\\n\\nfor i in range(11):\\n  if i == 9:\\n        i = '09'\\n  \\n  img = np.load(f'/home/fonta42/Desktop/interpretacao-redes-neurais/experiments/fullfilment_images_augmented/image_{i}.npy')\\n  \\n  fulfillment_images.append(np.clip(img, 0, 0.00001))\\n\\nfulfillment_images = np.array(fulfillment_images)\\n\\nfulfillment_images.shape \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fullfilment_images_augmented\n",
    "\"\"\" \n",
    "fulfillment_images = []\n",
    "\n",
    "for i in range(11):\n",
    "  if i == 9:\n",
    "        i = '09'\n",
    "  \n",
    "  img = np.load(f'/home/fonta42/Desktop/interpretacao-redes-neurais/experiments/fullfilment_images_augmented/image_{i}.npy')\n",
    "  \n",
    "  fulfillment_images.append(np.clip(img, 0, 0.00001))\n",
    "\n",
    "fulfillment_images = np.array(fulfillment_images)\n",
    "\n",
    "fulfillment_images.shape \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 128, 128)\n",
      "(11, 128, 128)\n",
      "(11, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Fullfilment images\n",
    "augmented_trained_fulfillment_images = []\n",
    "pre_trained_fulfillment_images = []\n",
    "non_trained_fulfillment_images = []\n",
    "\n",
    "\n",
    "for i in range(11):\n",
    "    augmented_img = np.load(f'/home/fonta42/Desktop/interpretacao-redes-neurais/experiments/torchseg_gradients/augmented_vessels_trained_model/image_{i}.npy')\n",
    "    augmented_trained_fulfillment_images.append(np.clip(augmented_img, 0, 0.00001))\n",
    "    \n",
    "    pre_img = np.load(f'/home/fonta42/Desktop/interpretacao-redes-neurais/experiments/torchseg_gradients/pre_trained_model/image_{i}.npy')\n",
    "    pre_trained_fulfillment_images.append(np.clip(augmented_img, 0, 0.00001))\n",
    "    \n",
    "    non_img = np.load(f'/home/fonta42/Desktop/interpretacao-redes-neurais/experiments/torchseg_gradients/non_trained_model/image_{i}.npy')\n",
    "    non_trained_fulfillment_images.append(np.clip(augmented_img, 0, 0.00001))\n",
    "\n",
    "augmented_trained_fulfillment_images = np.array(augmented_trained_fulfillment_images)\n",
    "pre_trained_fulfillment_images = np.array(pre_trained_fulfillment_images)\n",
    "non_trained_fulfillment_images = np.array(non_trained_fulfillment_images)\n",
    "\n",
    "print(augmented_trained_fulfillment_images.shape)\n",
    "print(pre_trained_fulfillment_images.shape)\n",
    "print(non_trained_fulfillment_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" gradient_path = f'/home/fonta42/Desktop/interpretacao-redes-neurais/experiments/torchseg_gradients/non_trained_model'\n",
    "fulfillment_images = non_trained_fulfillment_images\n",
    "model = unet_restnet_model \"\"\"\n",
    "\n",
    "\"\"\" gradient_path = f'/home/fonta42/Desktop/interpretacao-redes-neurais/experiments/torchseg_gradients/pre_trained_model'\n",
    "fulfillment_images = pre_trained_fulfillment_images\n",
    "model = pretrained_unet_restnet_model \"\"\"\n",
    "\n",
    "\n",
    "gradient_path = f'/home/fonta42/Desktop/interpretacao-redes-neurais/experiments/torchseg_gradients/augmented_vessels_trained_model'\n",
    "fulfillment_images = augmented_trained_fulfillment_images\n",
    "model = model_augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gradients_with_bounding_box(gradient, model_name, threshold=0.01):\n",
    "    gradient = gradient.squeeze()\n",
    "    mask = np.abs(gradient) > threshold\n",
    "    non_zero_coords = np.nonzero(mask)\n",
    "    \n",
    "    if len(non_zero_coords[0]) > 0:\n",
    "        y_min, y_max = non_zero_coords[0].min(), non_zero_coords[0].max()\n",
    "        x_min, x_max = non_zero_coords[1].min(), non_zero_coords[1].max()\n",
    "        num_pixels_above_threshold = np.sum(mask)\n",
    "        bounding_box_area = (y_max - y_min + 1) * (x_max - x_min + 1)\n",
    "        fulfillment = num_pixels_above_threshold / bounding_box_area\n",
    "\n",
    "        # Create the figure using Plotly Express\n",
    "        fig = px.imshow(\n",
    "            gradient[y_min:y_max+1, x_min:x_max+1],\n",
    "            title=f'Gradient Analysis for {model_name}',\n",
    "            labels={'x': 'x-axis', 'y': 'y-axis'},\n",
    "            color_continuous_scale=px.colors.diverging.RdYlGn,\n",
    "            range_color=[-np.abs(gradient).max(), np.abs(gradient).max()],\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            annotations=[{\n",
    "                'text': f\"Pixels: {num_pixels_above_threshold}<br>\"\n",
    "                        f\"X(min, max): ({x_min}, {x_max})<br>\"\n",
    "                        f\"Y(min, max): ({y_min}, {y_max})<br>\"\n",
    "                        f\"Area: {bounding_box_area}<br>\"\n",
    "                        f\"Fulfillment: {fulfillment:.2f}<br>\"\n",
    "                        f\"Threshold: {threshold:.6f}<br>\",\n",
    "                        \n",
    "                'showarrow': False,\n",
    "                'xref': 'paper',\n",
    "                'yref': 'paper',\n",
    "                'x': 0, 'y': 1,\n",
    "                'xanchor': 'left', 'yanchor': 'top',\n",
    "                'font': {'size': 12, 'color': 'black'},\n",
    "                'bgcolor': 'white',\n",
    "                'opacity': 0.7\n",
    "            }],\n",
    "            xaxis={'visible': False},\n",
    "            yaxis={'visible': False},\n",
    "        )\n",
    "        return fig\n",
    "    else:\n",
    "        return px.imshow(torch.zeros(128, 128), color_continuous_scale=px.colors.sequential.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x783a6df9be90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div(\n",
    "    style={\n",
    "        'display': 'flex',\n",
    "        'flex-direction': 'column',\n",
    "        'align-items': 'center',\n",
    "        'height': '95vh',  # Reduced height to account for borders\n",
    "        'width': '95vw',   # Reduced width to account for borders\n",
    "        'padding': '10px',  # Add some padding\n",
    "        'margin': 'auto',  # Center the div\n",
    "        'box-shadow': '0 4px 8px 0 rgba(0, 0, 0, 0.2)',  # Add a shadow for better visuals\n",
    "        'background-color': '#f9f9f9',  # Change background color for better contrast\n",
    "        'border-radius': '15px',  # Add border radius\n",
    "    },\n",
    "    children=[\n",
    "        html.H1(\"Dynamic Gradient Plots\", style={'margin-bottom': '20px'}),\n",
    "        html.Div(id='hover-data', style={'display': 'none'}),\n",
    "        html.Div(\n",
    "            style={\n",
    "                'display': 'flex',\n",
    "                'flex-direction': 'row',\n",
    "                'justify-content': 'space-around',\n",
    "                'width': '95vw',\n",
    "                'margin-bottom': '20px',\n",
    "            },\n",
    "            children=[\n",
    "                dcc.Dropdown(\n",
    "                    id='image-dropdown',\n",
    "                    options=[{'label': f'Image {i}', 'value': i} for i in range(len(original_images))],\n",
    "                    value=0,\n",
    "                    style={\n",
    "                        'width': '30vw',\n",
    "                        'margin-right': '10px',\n",
    "                        'background-color': '#fff',  # White background for better visibility\n",
    "                        'border-radius': '15px',\n",
    "                    }\n",
    "                ),\n",
    "                dcc.Input(\n",
    "                    id='threshold-input',\n",
    "                    type='number',\n",
    "                    placeholder='Porcentage of max value of gradient as threshold',\n",
    "                    min=0.001,\n",
    "                    max=100,\n",
    "                    style={\n",
    "                        'width': '30vw',\n",
    "                        'margin-right': '10px',\n",
    "                        'padding': '5px',  # Add some padding for better appearance\n",
    "                        'border-radius': '15px',\n",
    "                    }\n",
    "                ),\n",
    "                html.Button(\n",
    "                    'Update',\n",
    "                    id='update-button',\n",
    "                    n_clicks=0,\n",
    "                    style={\n",
    "                        'width': '30vw',\n",
    "                        'padding': '5px',  # Add some padding for better appearance\n",
    "                        'background-color': '#007bff',  # Bootstrap primary color\n",
    "                        'color': '#fff',  # White text color\n",
    "                        'border': 'none',  # Remove default border\n",
    "                        'cursor': 'pointer',  # Change cursor to pointer on hover\n",
    "                        'border-radius': '15px',\n",
    "                    }\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        html.Div(\n",
    "            style={\n",
    "                'display': 'flex',\n",
    "                'flex-direction': 'row',\n",
    "                'width': '95vw',  # Use 100% of the width\n",
    "                'height': '95vh',  # Adjust the height as needed\n",
    "            },\n",
    "            children=[\n",
    "                html.Div(\n",
    "                    style={\n",
    "                        'display': 'flex',\n",
    "                        'flex-direction': 'column',\n",
    "                        'align-items': 'center',\n",
    "                        'flex': '1',\n",
    "                        'margin-right': '2%',\n",
    "                        'border-radius': '15px'\n",
    "                    },\n",
    "                    children=[\n",
    "                        html.H3(\"Original Image\", style={'padding':'10px'}),\n",
    "                        dcc.Graph(\n",
    "                            id='image-display',\n",
    "                            config={'displayModeBar': True},\n",
    "                            style={'height': '80%', 'width': '100%'}\n",
    "                        )\n",
    "                    ]\n",
    "                ),\n",
    "                html.Div(\n",
    "                    style={\n",
    "                        'display': 'flex',\n",
    "                        'flex-direction': 'column',\n",
    "                        'align-items': 'center',\n",
    "                        'flex': '1',\n",
    "                        'margin-right': '2%',\n",
    "                        'border-radius': '15px'\n",
    "                    },\n",
    "                    children=[\n",
    "                        html.H3(\"Normalized quantity of pixels above 1% of max value for gradient at (x,y)\"),\n",
    "                        dcc.Graph(\n",
    "                            id='fulfillment-image-display',\n",
    "                            config={'displayModeBar': True},\n",
    "                            style={'height': '80%', 'width': '100%'}\n",
    "                        )\n",
    "                    ]\n",
    "                ),\n",
    "                html.Div(\n",
    "                    style={\n",
    "                        'display': 'flex',\n",
    "                        'flex-direction': 'column',\n",
    "                        'align-items': 'center',\n",
    "                        'flex': '1',\n",
    "                        'margin-right': '2%',\n",
    "                        'border-radius': '15px'\n",
    "                    },\n",
    "                    children=[\n",
    "                        html.H3(\"Model Mask\", style={'padding':'10px'}),\n",
    "                        dcc.Graph(\n",
    "                            id='model-mask-display',\n",
    "                            config={'displayModeBar': True},\n",
    "                            style={'height': '80%', 'width': '100%'}\n",
    "                        )\n",
    "                    ]\n",
    "                ),\n",
    "                html.Div(\n",
    "                    style={\n",
    "                        'display': 'flex',\n",
    "                        'flex-direction': 'column',\n",
    "                        'align-items': 'center',\n",
    "                        'flex': '1',\n",
    "                        'margin-right': '2%',\n",
    "                        'border-radius': '15px'\n",
    "                    },\n",
    "                    children=[\n",
    "                        html.H3(id='hover-coordinates', children='Coordinates: (x, y)', style={'padding':'10px'}),\n",
    "                        dcc.Graph(\n",
    "                            id='result-image-display',\n",
    "                            config={'displayModeBar': True},\n",
    "                            style={'height': '80%', 'width': '100%'}\n",
    "                        )\n",
    "                    ]\n",
    "                ),\n",
    "                html.Div(\n",
    "                    style={\n",
    "                        'display': 'flex',\n",
    "                        'flex-direction': 'column',\n",
    "                        'align-items': 'center',\n",
    "                        'flex': '1',\n",
    "                        'border-radius': '15px'\n",
    "                    },\n",
    "                    children=[\n",
    "                        html.H3(id='threshold-title', children=\"Pixels of gradient above Threshold: 0)\"),\n",
    "                        dcc.Graph(\n",
    "                            id='gradient-display',\n",
    "                            config={'displayModeBar': True},\n",
    "                            style={'height': '80%', 'width': '100%'}\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Callback to update the original image based on the dropdown selection\n",
    "@app.callback(\n",
    "    Output('image-display', 'figure'),\n",
    "    Output('fulfillment-image-display', 'figure'),\n",
    "    Output('model-mask-display', 'figure'),\n",
    "    Input('image-dropdown', 'value'),\n",
    ")\n",
    "def update_images(selected_index):\n",
    "    original_image_data = original_images[selected_index].cpu().numpy()\n",
    "    \n",
    "    fulfillment_image_data = fulfillment_images[selected_index]\n",
    "    \n",
    "    original_fig = px.imshow(original_image_data, color_continuous_scale=px.colors.sequential.gray)\n",
    "    \n",
    "    model_mask = model(original_images[selected_index].unsqueeze(0).unsqueeze(0))\n",
    "    fulfillment_image_data *= model_mask.argmax(dim=1).squeeze(0).detach().cpu().numpy()\n",
    "    fulfillment_fig = px.imshow(fulfillment_image_data, color_continuous_scale=px.colors.diverging.RdYlGn)\n",
    "    \n",
    "    softmax_probs = F.softmax(model_mask, dim=1)\n",
    "    class_one_probs = softmax_probs[0, 1, :, :].detach().cpu().numpy()\n",
    "\n",
    "    model_fig = px.imshow(class_one_probs, color_continuous_scale=px.colors.diverging.RdYlGn)\n",
    "    \n",
    "    return original_fig, fulfillment_fig,model_fig\n",
    "\n",
    "# Define callback to update the hover data\n",
    "@app.callback(\n",
    "    Output('hover-data', 'children'),\n",
    "    Input('image-display', 'hoverData'),\n",
    "    Input('fulfillment-image-display', 'hoverData')\n",
    ")\n",
    "def store_hover_data(hover_data_original, hover_data_fulfillment):\n",
    "    hover_data = hover_data_original or hover_data_fulfillment\n",
    "    if hover_data:\n",
    "        return json.dumps({'x': hover_data['points'][0]['x'], 'y': hover_data['points'][0]['y']})\n",
    "    return \"{}\"\n",
    "\n",
    "# Define callback to update the hover coordinates display\n",
    "@app.callback(\n",
    "    Output('hover-coordinates', 'children'),\n",
    "    Input('hover-data', 'children')\n",
    ")\n",
    "def update_hover_coordinates(hover_data_json):\n",
    "    hover_data = json.loads(hover_data_json)\n",
    "    if hover_data:\n",
    "        x, y = hover_data['x'], hover_data['y']\n",
    "        return f'Full Gradient, at Coordinates: ({x}, {y})'\n",
    "    return 'Full Gradient, Coordinates: (x, y)'\n",
    "\n",
    "# Define callback to update the result image\n",
    "@app.callback(\n",
    "    Output('result-image-display', 'figure'),\n",
    "    Input('update-button', 'n_clicks'),\n",
    "    Input('hover-data', 'children'),\n",
    "    Input('image-dropdown', 'value'),\n",
    ")\n",
    "def update_image(n_clicks, hover_data_json, selected_index):\n",
    "    hover_data = json.loads(hover_data_json)\n",
    "    if hover_data:\n",
    "        x, y = hover_data['x'], hover_data['y']\n",
    "        loaded_gradient = torch.load(f'{gradient_path}/jacobian_gradient_{selected_index}.pt')\n",
    "        \n",
    "        max_val = torch.max(torch.abs(loaded_gradient)).cpu().item()\n",
    "        #max_val = np.max([np.max(gradient) for gradient in gradient])\n",
    "        fig = px.imshow(loaded_gradient[y,x].to('cpu'), color_continuous_scale=px.colors.diverging.RdYlGn, range_color=[-max_val, max_val])\n",
    "        return fig\n",
    "    return px.imshow(torch.zeros(128, 128), color_continuous_scale=px.colors.diverging.RdYlGn)\n",
    "\n",
    "# Define callback to update the gradient display and the threshold title\n",
    "@app.callback(\n",
    "    Output('gradient-display', 'figure'),\n",
    "    Output('threshold-title', 'children'),\n",
    "    Input('hover-data', 'children'),\n",
    "    Input('threshold-input', 'value'),\n",
    "    Input('image-dropdown', 'value')\n",
    ")\n",
    "def update_gradient_display(hover_data_json, threshold, selected_index):\n",
    "    hover_data = json.loads(hover_data_json)\n",
    "    if hover_data:\n",
    "        x, y = hover_data['x'], hover_data['y']\n",
    "        loaded_gradient = torch.load(f'{gradient_path}/jacobian_gradient_{selected_index}.pt')\n",
    "        max_val = torch.max(torch.abs(loaded_gradient)).cpu().item()\n",
    "        \n",
    "        threshold = threshold if threshold is not None else 0.01\n",
    "        threshold_val = (threshold / 100) * max_val\n",
    "\n",
    "        # Return the gradient with the diverging color map\n",
    "        fig = plot_gradients_with_bounding_box(loaded_gradient[x,y].to('cpu').numpy(),\"Model\", threshold=threshold_val)\n",
    "        fig.update_layout(\n",
    "            title=f\"Pixels of gradient above Threshold: {threshold_val:.4f}\"\n",
    "        )\n",
    "        return fig, f\"Pixels of gradient above Threshold: {threshold_val:.4f}\"\n",
    "    return px.imshow(torch.zeros(128, 128), color_continuous_scale=px.colors.diverging.RdYlGn), \"Pixels of gradient above Threshold: 0\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Imagens de Vasos Sanguíneos\n",
    "\n",
    "## Imagem 0:\n",
    "\n",
    "- Gradiente bastante estável;\n",
    "- Valores altos para região de falha de vaso, região (25,34);\n",
    "- Valores altos para borda superior direita (63,1), região que parece ter um vaso escondido, rede até chegou a classificar como vaso;\n",
    "- Pequena variação na borda inferior centro (38,63), parece ser uma pequena parte de um vaso;\n",
    "- No geral, gradientes maiores em regiões onde aparenta ter uma descontinuação de um vaso.\n",
    "\n",
    "## Imagem 1:\n",
    "\n",
    "- Valores altos nas bordas do vaso, região (27,28);\n",
    "- Valores altos na região (28,60), parece ser uma descontinuação de um vaso;\n",
    "- Valores altos na região (5,28), parece ser a ponta de um vaso sanguíneo;\n",
    "- Valores de gradiente alto na região (63,3), também parece ser a ponta de um vaso;\n",
    "- Valores altos na região (16,45), parece algo entre a borda de um vaso e uma possível descontinuação do mesmo vaso.\n",
    "\n",
    "## Imagem 2:\n",
    "\n",
    "- Valores altos nos ruídos e descontinuação do vaso região entre (12,18) até (28,30);\n",
    "- No geral, valores altos nas bordas e na transição entre a borda de um vaso sanguíneo e o fundo.\n",
    "\n",
    "## Imagem 3:\n",
    "\n",
    "- Valores altos na região (45,33), parece ser algo entre a borda do vaso sanguíneo e uma possível descontinuação;\n",
    "- Valores altos na região (61,43), no geral, parece ser um comportamento padrão de gradiente com valores altos para regiões onde a probabilidade de ser um vaso fica próximo a 50%, regiões onde a rede não dá uma probabilidade para nenhuma das duas possíveis targets;\n",
    "- Valores altos na região (2,15), mesma questão da observação acima.\n",
    "\n",
    "## Imagem 4:\n",
    "\n",
    "- Valores altos em um ruído com destaque no fundo da imagem, região (39,44), mesma observação de parece ser uma zona de \"dúvida\" da rede neural;\n",
    "- Valores altos na região (62,57), mesmo caso das anteriores, região com probabilidades em torno de 50%;\n",
    "- Região (58,3), (8,1), mesmo comportamento.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpreting-cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
