{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"../models/\")\n",
    "from CustomCNNVessel import CustomResNet\n",
    "\n",
    "def get_all_gradients(model, image, sampling_rate=1, device=\"cuda\", vectorize=False):\n",
    "\n",
    "    model.to(device)\n",
    "    model = model.eval()\n",
    "    model_wrapped = wrapper(model)\n",
    "    sampled_image = image[:,::sampling_rate,::sampling_rate]\n",
    "    sampled_image = sampled_image.to(device).unsqueeze(0)\n",
    "    sampled_image.requires_grad = True\n",
    "\n",
    "    jacobian = torch.autograd.functional.jacobian(model_wrapped, \n",
    "                                                            sampled_image,\n",
    "                                                            vectorize = vectorize)\n",
    "    jacobian = jacobian.squeeze().to('cpu')\n",
    "    return jacobian\n",
    "\n",
    "def wrapper(model):\n",
    "    '''Wrap model to return probabilities and only the vessel channel.'''\n",
    "    def new_model(img):\n",
    "        out = model(img)\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        return probs[:,1]\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" #Normal Vessels \\nimport os\\nfrom PIL import Image\\nimport numpy as np\\n\\n# Carregando as imagens\\ndef load_images_from_directory(directory_name):\\n    image_files = sorted(os.listdir(directory_name))\\n\\n    images = []\\n    for file_name in image_files:\\n        if file_name.endswith('.png'):\\n            img_path = os.path.join(directory_name, file_name)\\n            img = Image.open(img_path)\\n            img_array = np.array(img) / 255.0\\n            images.append(img_array)\\n\\n    return torch.tensor(np.array(images), dtype=torch.float).unsqueeze(1).to('cpu') # Salvando as imagens na RAM porque a VRAM da gpu é liberada a cada cálculo\\n  \\noriginal_images = load_images_from_directory('./cropped_images')\\noriginal_images.shape \""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" #Normal Vessels \n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Carregando as imagens\n",
    "def load_images_from_directory(directory_name):\n",
    "    image_files = sorted(os.listdir(directory_name))\n",
    "\n",
    "    images = []\n",
    "    for file_name in image_files:\n",
    "        if file_name.endswith('.png'):\n",
    "            img_path = os.path.join(directory_name, file_name)\n",
    "            img = Image.open(img_path)\n",
    "            img_array = np.array(img) / 255.0\n",
    "            images.append(img_array)\n",
    "\n",
    "    return torch.tensor(np.array(images), dtype=torch.float).unsqueeze(1).to('cpu') # Salvando as imagens na RAM porque a VRAM da gpu é liberada a cada cálculo\n",
    "  \n",
    "original_images = load_images_from_directory('./cropped_images')\n",
    "original_images.shape \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1, 128, 128])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Augmented Vessels\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Carregando as imagens\n",
    "def load_images_from_directory(directory_name, image_list = []):\n",
    "    image_files = sorted(os.listdir(directory_name))\n",
    "\n",
    "    images = []\n",
    "    for file_name in image_files:\n",
    "        if file_name.endswith('.tiff'):\n",
    "            img_path = os.path.join(directory_name, file_name)\n",
    "            image_list.append(img_path)\n",
    "            img = Image.open(img_path)\n",
    "            img_array = np.array(img) / 255.0\n",
    "            images.append(img_array)\n",
    "\n",
    "    return torch.tensor(np.array(images), dtype=torch.float).unsqueeze(1).to('cpu'), image_list # Salvando as imagens na RAM porque a VRAM da gpu é liberada a cada cálculo\n",
    "  \n",
    "original_images,  image_list = load_images_from_directory(\"/home/fonta42/Desktop/interpretacao-redes-neurais/data/augmented_vessels\")\n",
    "original_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # instanciando o modelo\\nmodel_layers = (1, 1, 1)\\nmodel_channels = (64, 64, 64)\\nmodel = torchtrainer.models.resunet.ResUNetV2((8,), (1,), (64,))\\n# carregando o state_dict\\nbaseline_state_dict = torch.load('./unetv2_baseline/checkpoint_best.pth')['model']\\nmodel.load_state_dict(baseline_state_dict) \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # instanciando o modelo\n",
    "model_layers = (1, 1, 1)\n",
    "model_channels = (64, 64, 64)\n",
    "model = torchtrainer.models.resunet.ResUNetV2((8,), (1,), (64,))\n",
    "# carregando o state_dict\n",
    "baseline_state_dict = torch.load('./unetv2_baseline/checkpoint_best.pth')['model']\n",
    "model.load_state_dict(baseline_state_dict) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchseg\n",
    "\n",
    "unet_restnet_model = torchseg.Unet(\n",
    "    encoder_name=\"resnet18\",\n",
    "    encoder_weights=True,\n",
    "    in_channels=1,\n",
    "    classes=2,\n",
    ").to('cuda')\n",
    "\n",
    "unet_restnet_model.load_state_dict(torch.load(\"/home/fonta42/Desktop/interpretacao-redes-neurais/models/torchseg/pretrained_unet_resnet.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m11\u001b[39m):\n\u001b[1;32m      4\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# Record the start time before extracting the gradient\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m get_all_gradients(unet_restnet_model, \n\u001b[1;32m      7\u001b[0m                                  original_images[idx], \n\u001b[1;32m      8\u001b[0m                                  sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(gradient\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mmax(gradient))\n",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m, in \u001b[0;36mget_all_gradients\u001b[0;34m(model, image, sampling_rate, device, vectorize)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(sampled_image\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     15\u001b[0m sampled_image\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m jacobian \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mjacobian(model_wrapped, \n\u001b[1;32m     18\u001b[0m                                                         sampled_image,\n\u001b[1;32m     19\u001b[0m                                                         vectorize \u001b[38;5;241m=\u001b[39m vectorize)\n\u001b[1;32m     20\u001b[0m jacobian \u001b[38;5;241m=\u001b[39m jacobian\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jacobian\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/functional.py:786\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    784\u001b[0m jac_i: Tuple[List[torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)))  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out\u001b[38;5;241m.\u001b[39mnelement()):\n\u001b[0;32m--> 786\u001b[0m     vj \u001b[38;5;241m=\u001b[39m _autograd_grad(\n\u001b[1;32m    787\u001b[0m         (out\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[j],),\n\u001b[1;32m    788\u001b[0m         inputs,\n\u001b[1;32m    789\u001b[0m         retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    790\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    791\u001b[0m     )\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el_idx, (jac_i_el, vj_el, inp_el) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;28mzip\u001b[39m(jac_i, vj, inputs)\n\u001b[1;32m    795\u001b[0m     ):\n\u001b[1;32m    796\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m vj_el \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/functional.py:192\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, create_graph, retain_graph, is_grads_batched)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(\n\u001b[1;32m    193\u001b[0m         new_outputs,\n\u001b[1;32m    194\u001b[0m         inputs,\n\u001b[1;32m    195\u001b[0m         new_grad_outputs,\n\u001b[1;32m    196\u001b[0m         allow_unused\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    197\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    198\u001b[0m         retain_graph\u001b[38;5;241m=\u001b[39mretain_graph,\n\u001b[1;32m    199\u001b[0m         is_grads_batched\u001b[38;5;241m=\u001b[39mis_grads_batched,\n\u001b[1;32m    200\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:412\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    408\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    409\u001b[0m         grad_outputs_\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     result \u001b[38;5;241m=\u001b[39m _engine_run_backward(\n\u001b[1;32m    413\u001b[0m         t_outputs,\n\u001b[1;32m    414\u001b[0m         grad_outputs_,\n\u001b[1;32m    415\u001b[0m         retain_graph,\n\u001b[1;32m    416\u001b[0m         create_graph,\n\u001b[1;32m    417\u001b[0m         inputs,\n\u001b[1;32m    418\u001b[0m         allow_unused,\n\u001b[1;32m    419\u001b[0m         accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    420\u001b[0m     )\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    423\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    425\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for idx in range(11):\n",
    "    start_time = time.time()  # Record the start time before extracting the gradient\n",
    "    \n",
    "    gradient = get_all_gradients(unet_restnet_model, \n",
    "                                 original_images[idx], \n",
    "                                 sampling_rate=1)\n",
    "    print(gradient.shape)\n",
    "    print(torch.max(gradient))\n",
    "    break\n",
    "    # Save the gradient\n",
    "    torch.save(gradient, f'./torchseg_gradients/jacobian_gradient_{idx}.pt')\n",
    "    \n",
    "    end_time = time.time()  # Record the end time after saving the gradient\n",
    "    elapsed_time = end_time - start_time  # Calculate the elapsed time\n",
    "    print(f\"Gradient {idx} extraction and saving took {elapsed_time:.2f} seconds.\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient 0 extraction and saving took 40.11 seconds.\n",
      "Gradient 1 extraction and saving took 38.89 seconds.\n",
      "Gradient 2 extraction and saving took 39.26 seconds.\n",
      "Gradient 3 extraction and saving took 39.24 seconds.\n",
      "Gradient 4 extraction and saving took 38.43 seconds.\n",
      "Gradient 5 extraction and saving took 38.53 seconds.\n",
      "Gradient 6 extraction and saving took 38.77 seconds.\n",
      "Gradient 7 extraction and saving took 38.65 seconds.\n",
      "Gradient 8 extraction and saving took 38.97 seconds.\n",
      "Gradient 9 extraction and saving took 41.89 seconds.\n",
      "Gradient 10 extraction and saving took 40.91 seconds.\n"
     ]
    }
   ],
   "source": [
    "import torchseg\n",
    "\n",
    "unet_restnet_model = torchseg.Unet(\n",
    "    encoder_name=\"resnet18\",\n",
    "    encoder_weights=False,\n",
    "    in_channels=1,\n",
    "    classes=2,\n",
    ").to('cuda')\n",
    "\n",
    "unet_restnet_model.load_state_dict(torch.load(\"/home/fonta42/Desktop/interpretacao-redes-neurais/models/torchseg/unet_resnet.pt\"))\n",
    "\n",
    "import time\n",
    "\n",
    "for idx in range(11):\n",
    "    start_time = time.time()  # Record the start time before extracting the gradient\n",
    "    \n",
    "    gradient = get_all_gradients(unet_restnet_model, \n",
    "                                 original_images[idx], \n",
    "                                 sampling_rate=1)\n",
    "    \n",
    "    # Save the gradient\n",
    "    torch.save(gradient, f'./torchseg_gradients/jacobian_gradient_{idx}.pt')\n",
    "    \n",
    "    end_time = time.time()  # Record the end time after saving the gradient\n",
    "    elapsed_time = end_time - start_time  # Calculate the elapsed time\n",
    "    \n",
    "    print(f\"Gradient {idx} extraction and saving took {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model_weighted\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/vess_map_regularized_none_200.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m   gradient \u001b[38;5;241m=\u001b[39m get_all_gradients(model_weighted, \n\u001b[1;32m      5\u001b[0m                                original_images[idx], \n\u001b[1;32m      6\u001b[0m                                sampling_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;66;03m# Salvando o gradiente\u001b[39;00m\n\u001b[1;32m      9\u001b[0m   torch\u001b[38;5;241m.\u001b[39msave(gradient, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./gradients_augmented_vessels/jacobian_gradient_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m, in \u001b[0;36mget_all_gradients\u001b[0;34m(model, image, sampling_rate, device, vectorize)\u001b[0m\n\u001b[1;32m     13\u001b[0m sampled_image \u001b[38;5;241m=\u001b[39m sampled_image\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m sampled_image\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m jacobian \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mjacobian(model_wrapped, \n\u001b[1;32m     17\u001b[0m                                                         sampled_image,\n\u001b[1;32m     18\u001b[0m                                                         vectorize \u001b[38;5;241m=\u001b[39m vectorize)\n\u001b[1;32m     19\u001b[0m jacobian \u001b[38;5;241m=\u001b[39m jacobian\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jacobian\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/functional.py:786\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    784\u001b[0m jac_i: Tuple[List[torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)))  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out\u001b[38;5;241m.\u001b[39mnelement()):\n\u001b[0;32m--> 786\u001b[0m     vj \u001b[38;5;241m=\u001b[39m _autograd_grad(\n\u001b[1;32m    787\u001b[0m         (out\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[j],),\n\u001b[1;32m    788\u001b[0m         inputs,\n\u001b[1;32m    789\u001b[0m         retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    790\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    791\u001b[0m     )\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el_idx, (jac_i_el, vj_el, inp_el) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;28mzip\u001b[39m(jac_i, vj, inputs)\n\u001b[1;32m    795\u001b[0m     ):\n\u001b[1;32m    796\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m vj_el \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/functional.py:192\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, create_graph, retain_graph, is_grads_batched)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(\n\u001b[1;32m    193\u001b[0m         new_outputs,\n\u001b[1;32m    194\u001b[0m         inputs,\n\u001b[1;32m    195\u001b[0m         new_grad_outputs,\n\u001b[1;32m    196\u001b[0m         allow_unused\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    197\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    198\u001b[0m         retain_graph\u001b[38;5;241m=\u001b[39mretain_graph,\n\u001b[1;32m    199\u001b[0m         is_grads_batched\u001b[38;5;241m=\u001b[39mis_grads_batched,\n\u001b[1;32m    200\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:412\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    408\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    409\u001b[0m         grad_outputs_\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     result \u001b[38;5;241m=\u001b[39m _engine_run_backward(\n\u001b[1;32m    413\u001b[0m         t_outputs,\n\u001b[1;32m    414\u001b[0m         grad_outputs_,\n\u001b[1;32m    415\u001b[0m         retain_graph,\n\u001b[1;32m    416\u001b[0m         create_graph,\n\u001b[1;32m    417\u001b[0m         inputs,\n\u001b[1;32m    418\u001b[0m         allow_unused,\n\u001b[1;32m    419\u001b[0m         accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    420\u001b[0m     )\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    423\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    425\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_weighted = CustomResNet(num_classes=2)\n",
    "model_weighted.load_state_dict(torch.load(f\"../models/vess_map_regularized_none_200.pth\"))\n",
    "for idx in range(4,11):\n",
    "  gradient = get_all_gradients(model_weighted, \n",
    "                               original_images[idx], \n",
    "                               sampling_rate = 1)\n",
    "  \n",
    "  # Salvando o gradiente\n",
    "  torch.save(gradient, f'./gradients_augmented_vessels/jacobian_gradient_{idx}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 64, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_gradient = torch.load(f'./gradients/jacobian_gradient_{1}.pt')\n",
    "loaded_gradient.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6746.3711)\n"
     ]
    }
   ],
   "source": [
    "rel_diff = ((loaded_gradient\n",
    " - jacobian)/jacobian).abs()\n",
    "max_diff = rel_diff[jacobian.abs()>1e-2].max()\n",
    "print(max_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageUF:\n",
    "    '''Represents a float tensor as uint8, storing the minimum and\n",
    "    maximum values.'''\n",
    "\n",
    "    def __init__(self, image=None):\n",
    "\n",
    "        if image is None:\n",
    "            self.min = None\n",
    "            self.max = None\n",
    "            self.image_uint8 = None\n",
    "        else:\n",
    "            min = image.min()\n",
    "            max = image.max()\n",
    "\n",
    "            image_norm = 255.*(image - min)/(max - min)\n",
    "            image_uint8 = image_norm.round().to(torch.uint8)\n",
    "            \n",
    "            self.min = min\n",
    "            self.max = max\n",
    "            self.image_uint8 = image_uint8\n",
    "\n",
    "    def state_dict(self):\n",
    "\n",
    "        state = {\n",
    "            'min': self.min,\n",
    "            'max': self.max,\n",
    "            'image_uint8': self.image_uint8\n",
    "        }\n",
    "\n",
    "        return state\n",
    "    \n",
    "    def load_state_dict(self, state):\n",
    "\n",
    "        self.min = state['min']\n",
    "        self.max = state['max']\n",
    "        self.image_uint8 = state['image_uint8']\n",
    "\n",
    "    def to_float(self):\n",
    "\n",
    "        min, max = self.min, self.max\n",
    "        image_float32_norm = self.image_uint8.to(torch.float32)\n",
    "        image_float32 = image_float32_norm*(max-min)/255. + min\n",
    "\n",
    "        return image_float32\n",
    "\n",
    "jacobian_uf = ImageUF(jacobian)\n",
    "# Save data\n",
    "torch.save(jacobian_uf.state_dict(), 'jacobian.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0279)\n"
     ]
    }
   ],
   "source": [
    "# Load data form disk\n",
    "jacobian_uf2 = ImageUF()\n",
    "jacobian_uf.load_state_dict(torch.load('jacobian.pt'))\n",
    "# Convert to float again\n",
    "jacobian_rec = jacobian_uf.to_float()\n",
    "\n",
    "# Check maximum relative difference between values larger than 0.01\n",
    "rel_diff = ((jacobian_rec - jacobian)/jacobian).abs()\n",
    "max_diff = rel_diff[jacobian.abs()>1e-2].max()\n",
    "print(max_diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
